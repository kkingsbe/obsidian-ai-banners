================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-08-22T17:21:30.091Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
.editorconfig
.eslintignore
.eslintrc
.gitignore
.npmrc
esbuild.config.mjs
lib/imagegen.ts
lib/imagegenv2.ts
lib/inputmodal.ts
lib/settingstab.ts
lib/types.ts
LICENSE
main.ts
manifest.json
package.json
README.md
styles.css
tsconfig.json
version-bump.mjs
versions.json

================================================================
Repository Files
================================================================

================
File: .editorconfig
================
# top-most EditorConfig file
root = true

[*]
charset = utf-8
end_of_line = lf
insert_final_newline = true
indent_style = tab
indent_size = 4
tab_width = 4

================
File: .eslintignore
================
node_modules/

main.js

================
File: .eslintrc
================
{
    "root": true,
    "parser": "@typescript-eslint/parser",
    "env": { "node": true },
    "plugins": [
      "@typescript-eslint"
    ],
    "extends": [
      "eslint:recommended",
      "plugin:@typescript-eslint/eslint-recommended",
      "plugin:@typescript-eslint/recommended"
    ], 
    "parserOptions": {
        "sourceType": "module"
    },
    "rules": {
      "no-unused-vars": "off",
      "@typescript-eslint/no-unused-vars": ["error", { "args": "none" }],
      "@typescript-eslint/ban-ts-comment": "off",
      "no-prototype-builtins": "off",
      "@typescript-eslint/no-empty-function": "off"
    } 
  }

================
File: .gitignore
================
# vscode
.vscode 

# Intellij
*.iml
.idea

# npm
node_modules

# Don't include the compiled main.js file in the repo.
# They should be uploaded to GitHub releases instead.
main.js

# Exclude sourcemaps
*.map

# obsidian
data.json

# Exclude macOS Finder (System Explorer) View States
.DS_Store

================
File: .npmrc
================
tag-version-prefix=""

================
File: esbuild.config.mjs
================
import esbuild from "esbuild";
import process from "process";
import builtins from "builtin-modules";

const banner =
`/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/
`;

const prod = (process.argv[2] === "production");

const context = await esbuild.context({
	banner: {
		js: banner,
	},
	entryPoints: ["main.ts"],
	bundle: true,
	external: [
		"obsidian",
		"electron",
		"@codemirror/autocomplete",
		"@codemirror/collab",
		"@codemirror/commands",
		"@codemirror/language",
		"@codemirror/lint",
		"@codemirror/search",
		"@codemirror/state",
		"@codemirror/view",
		"@lezer/common",
		"@lezer/highlight",
		"@lezer/lr",
		...builtins],
	format: "cjs",
	target: "es2018",
	logLevel: "info",
	sourcemap: prod ? false : "inline",
	treeShaking: true,
	outfile: "main.js",
});

if (prod) {
	await context.rebuild();
	process.exit(0);
} else {
	await context.watch();
}

================
File: lib/imagegen.ts
================
import { OpenAI } from 'openai'
import * as fal from "@fal-ai/serverless-client";
import { Notice } from 'obsidian';
import { DocumentInfo } from './types';

const systemPrompt = `
Create a prompt to be used by an AI image generator in order to create a banner for an Obsidian document. The markdown document of the file will be provided, along with user-provided context as to what the documents purpose is. The name of the document does not need to be provided in the image prompt, and assume the image generator has no background information or context. Respond with only the prompt for image generation, and use the below guide to help design the prompt.

I. Basic Prompt Structure
[Subject] [Action/Pose] [Setting] [Style] [Additional Details]
II. Expanded Prompt Elements
Subject: The main focus of the image
Example: "A majestic lion", "A futuristic cityscape", "A bouquet of wildflowers"
Action/Pose (if applicable): What the subject is doing
Example: "standing proudly", "bustling with flying cars", "arranged in a vintage vase"
Setting: Where the scene takes place
Example: "on a savannah at sunset", "under a purple sky", "on a rustic wooden table"
Style: Artistic style or medium
Example: "photorealistic", "oil painting", "watercolor sketch"
Additional Details:
Lighting: "soft ambient light", "harsh shadows", "golden hour glow"
Color palette: "muted earth tones", "vibrant neon colors", "pastel shades"
Mood: "serene", "mysterious", "joyful", "melancholic"
Composition: "close-up", "wide angle", "bird's eye view"
III. Creating Realistic, Non-Clipart Images
Specify realistic styles:
Use terms like "photorealistic", "hyperrealistic", or "lifelike"
Example: "Create a photorealistic image of a snow-capped mountain"
Add texture details:
Mention specific textures to add depth and realism
Example: "rough tree bark", "smooth polished marble", "weathered leather"
Emphasize complex lighting:
Describe sophisticated lighting scenarios
Example: "soft diffused sunlight filtering through morning mist"
Include subtle imperfections:
Add slight flaws or asymmetries for a more natural look
Example: "an old pocket watch with a slightly scratched face"
Mention photographic techniques:
Use terms like "shallow depth of field", "long exposure", or "macro photography"
Example: "Capture the flower with a macro lens, focusing on the delicate stamens"
Avoid cartoonish terms:
Steer clear of words like "cartoon", "clipart", or "vector"
Instead, use terms like "detailed illustration" or "precise drawing" if you want a non-photorealistic style
Specify materials and fine details:
Mention specific materials and intricate details
Example: "a hand-blown Murano glass vase with swirling patterns of blue and gold"
IV. Avoiding Overdetailed or Cluttered Images
Use "focus on" or "emphasize" phrases:
Example: "Focus on the lion's face" or "Emphasize the lighthouse structure"
This helps direct the AI's attention to the main subject
Specify a simple background:
Example: "with a blurred forest background" or "against a plain white backdrop"
This can help prevent the AI from adding unnecessary details
Limit the number of elements in your prompt:
Instead of describing multiple objects, stick to one or two main elements
Example: "A single red rose in a clear glass vase" rather than "A bouquet of various flowers in a decorated room"
Use negative prompts:
Explicitly state what you don't want in the image
Example: "A cityscape at night, no people, no vehicles"
Specify the composition:
Use terms like "close-up", "medium shot", or "wide angle" to control how much of the scene is shown
Example: "A close-up portrait of an elderly man, focusing on his weathered face"
Avoid certain trigger words:
Some words might prompt the AI to add unwanted elements
For instance, avoid words like "map", "diagram", or "layout" unless you specifically want these elements
Use simplicity-oriented style words:
Incorporate terms like "minimalist", "clean", or "uncluttered" in your prompt
Example: "A minimalist landscape showing a single tree on a hill"
Iterate and refine:
If you get an overdetailed result, try simplifying your prompt and regenerating the image
V. Example Prompts
Basic prompt: "A majestic lion standing proudly on a savannah at sunset, oil painting style with warm earth tones and dramatic lighting."
Realistic, non-clipart prompt: "A weathered lighthouse on a rocky coast, photorealistic style, with detailed textures of peeling paint and rusted metal. Dramatic lighting with the warm glow of sunset casting long shadows. Capture the scene using a wide-angle lens perspective with a slightly tilted horizon for dynamic composition."
Detailed, artistic prompt: "A close-up of a dewdrop on a spider's web, hyperrealistic style. Capture the refraction of light through the water droplet, revealing a distorted image of the background forest. Use macro photography techniques to emphasize the intricate details of the silk strands. Soft, diffused morning light creates a dreamy atmosphere with a cool color palette dominated by blues and greens."
Focused, uncluttered prompt: "Close-up portrait of a lion, emphasizing its majestic mane. Simple, blurred savannah background. Photorealistic style with warm lighting. Focus on the lion's face, avoiding any additional elements."
VI. General Tips for Effective Prompts
Be specific and descriptive in your language
Use vivid adjectives and adverbs to convey your vision
Combine unexpected elements for unique and interesting results
Experiment with different styles and moods
Refine your prompt based on the generated results, iterating as necessary
Balance detail with focus to avoid cluttered or overcomplex images
Use the structure and tips provided, but don't be afraid to experiment and find what works best for you

Again, Respond with only the prompt for image generation`

export class ImageGen {
    private openaiClient: OpenAI;

    constructor(fal_key: string, openai_key: string) {
        fal.config({
            credentials: fal_key
        });
        this.openaiClient = new OpenAI({
            apiKey: openai_key,
            dangerouslyAllowBrowser: true
        });
    }

    async generate(additionalContext: string, docInfo: DocumentInfo): Promise<string> {
        try {
            new Notice("Generating prompt...")
            const imagePrompt = await this.generateImagePrompt(`ADDITIONAL DOCUMENT INFORMATION PROVIDED BY USER: ${additionalContext}\n# ${docInfo.title}\n${docInfo.content}`);
            new Notice("Generated prompt: " + imagePrompt.slice(0, 100) + "...")

            new Notice("Generating image...")
            const imageUrl = await this.generateImage(imagePrompt);
            new Notice("Generated image: " + imageUrl.slice(0, 100) + "...")
            return imageUrl;
        } catch (error) {
            new Notice("Error generating image:", error);
            throw error;
        }
    }

    private async generateImagePrompt(markdownDocument: string): Promise<string> {
        try {
            const response = await this.openaiClient.chat.completions.create({
                model: "gpt-4o",
                messages: [
                    {
                        role: "system",
                        content: systemPrompt
                    },
                    {
                        role: "user",
                        content: markdownDocument
                    }
                ],
                max_tokens: 100,
                temperature: 0.7,
                n: 1
            });

            if (response.choices && response.choices.length > 0) {
                return response.choices[0].message.content?.trim() || "";
            } else {
                throw new Error("No image prompt generated");
            }
        } catch (error) {
            console.error("Error generating image prompt:", error);
            throw error;
        }
    }

    private async generateImage(imagePrompt: string): Promise<string> {
        const result = await fal.subscribe("fal-ai/flux/schnell", {
            input: {
                prompt: imagePrompt,
                image_size: {
                    width: 2000,
                    height: 300
                },
                num_inference_steps: 12
            },
            logs: true,
            onQueueUpdate: (update) => {
                if (update.status === "IN_PROGRESS") {
                    update.logs.map((log) => log.message).forEach(console.log);
                }
            },
        });

        console.log(result);

        return (result as any).images[0].url
    }
}

================
File: lib/imagegenv2.ts
================
import { OpenAI } from 'openai'
import * as fal from "@fal-ai/serverless-client";
import { Notice } from 'obsidian';
import { DocumentInfo } from './types';
import * as fs from 'fs';
import { Readable } from 'stream';

const imageDescriptionPrompt = `
Determine what image would make an appealing yet appropriate banner for the provided markdown document, and then generate a highly accurate and detailed description of the image. Pay close attention to the context within the source material to ensure the description captures the item or scene's specific and intended purpose, appearance, and function. Avoid relying on common associations or stereotypes related to the terminology used and focus instead on the unique characteristics as described or depicted in the original source. If the item or scene has unconventional or non-standard features, emphasize these aspects to maintain fidelity to the original intent and description.
`

const imageGenerationPrompt = `
You are an AI that generates detailed image descriptions for an AI image generator. When provided with a description, expand it into a comprehensive and vivid prompt. Include specific details about the subject, environment, style, lighting, mood, and any additional elements to create a clear and precise image prompt. Ensure that the description is detailed enough to guide the image generator in producing a high-quality and accurate image
`

interface ImageGenResult {
    imageUrl: string;
    imageDescription: string;
    imagePrompt: string;
}

export class ImageGen {
    private openaiClient: OpenAI;

    constructor(fal_key: string, openai_key: string) {
        fal.config({
            credentials: fal_key
        });
        this.openaiClient = new OpenAI({
            apiKey: openai_key,
            dangerouslyAllowBrowser: true
        });
    }

    async generate(additionalContext: string, docInfo: DocumentInfo, type: "banner"|"inline"): Promise<ImageGenResult> {
        try {
            new Notice("Generating image description...")
            const imageDescription = await this.generateImageDescription(`ADDITIONAL DOCUMENT INFORMATION PROVIDED BY USER: ${additionalContext}\n# ${docInfo.title}\n${docInfo.content}`);
            new Notice("Generated image description: " + imageDescription.slice(0, 100) + "...")
            new Notice("Generating prompt...")
            const imagePrompt = await this.generateImagePrompt(imageDescription);
            new Notice("Generated prompt: " + imagePrompt.slice(0, 100) + "...")

            new Notice("Generating image...")
            const imageUrl = await this.generateImage(imagePrompt, type);
            new Notice("Generated image: " + imageUrl.slice(0, 100) + "...")
            return { imageUrl, imageDescription, imagePrompt };
        } catch (error) {
            new Notice("Error generating image:", error);
            throw error;
        }
    }

    async generateRevised(imageDescription: string, previousImagePrompt: string, imageUrl: string): Promise<ImageGenResult> {
        try {
            const newPrompt = await this.generateRevisedImagePrompt(imageDescription, previousImagePrompt, imageUrl);
            new Notice("Generated revised image prompt: " + newPrompt.slice(0, 100) + "...")

            new Notice("Generating revised image...")
            const newImageUrl = await this.generateImage(newPrompt, "banner");
            new Notice("Generated revised image: " + newImageUrl.slice(0, 100) + "...")
            return { imageUrl: newImageUrl, imageDescription, imagePrompt: newPrompt };
        } catch (e) {
            new Notice("Error generating revised image:", e);
            throw e;
        }
    }

    private async generateImageDescription(markdownDocument: string): Promise<string> {
        try {
            const response = await this.openaiClient.chat.completions.create({
                model: "gpt-4o",
                messages: [
                    {
                        role: "system",
                        content: imageDescriptionPrompt
                    },
                    {
                        role: "user",
                        content: markdownDocument
                    }
                ],
                max_tokens: 2000,
                temperature: 0.7,
                n: 1
            });

            if (response.choices && response.choices.length > 0) {
                return response.choices[0].message.content?.trim() || "";
            } else {
                throw new Error("No image description generated");
            }
        } catch (error) {
            console.error("Error generating image description:", error);
            throw error;
        }
    }

    private async uploadImageToOpenai(imageUrl: string): Promise<string> {
        try {
            const res = await this.openaiClient.files.create({ file: await fetch(imageUrl), purpose: "vision" });
            return res.id;
        } catch (error) {
            console.error("Error uploading image to OpenAI:", error);
            throw error;
        }
    }

    private async generateRevisedImagePrompt(imageDescription: string, previousImagePrompt: string, imageUrl: string): Promise<string> {
        const id = await this.uploadImageToOpenai(imageUrl);
        
        try {
            const response = await this.openaiClient.chat.completions.create({
                model: "gpt-4o",
                messages: [
                    {
                        role: "system",
                        content: imageGenerationPrompt
                    },
                    {
                        role: "user",
                        content: imageDescription
                    },
                    {
                        role: "assistant",
                        content: previousImagePrompt
                    },
                    {
                        role: "assistant",
                        content: `<image: ${id}>`
                    },
                    {
                        role: "user",
                        content: "Does this image fit what you were trying to generate? If not, produce an updated image generation prompt."
                    }
                ],
                max_tokens: 2000,
                temperature: 0.7,
                n: 1
            });

            if (response.choices && response.choices.length > 0) {
                return response.choices[0].message.content?.trim() || "";
            } else {
                throw new Error("No revised image prompt generated");
            }
        } catch (error) {
            console.error("Error generating revised image prompt:", error);
            throw error;
        }
    }

    private async generateImagePrompt(imageDescription: string): Promise<string> {
        try {
            const response = await this.openaiClient.chat.completions.create({
                model: "gpt-4o",
                messages: [
                    {
                        role: "system",
                        content: imageGenerationPrompt
                    },
                    {
                        role: "user",
                        content: imageDescription
                    }
                ],
                max_tokens: 2000,
                temperature: 0.7,
                n: 1
            });

            if (response.choices && response.choices.length > 0) {
                return response.choices[0].message.content?.trim() || "";
            } else {
                throw new Error("No image prompt generated");
            }
        } catch (error) {
            console.error("Error generating image prompt:", error);
            throw error;
        }
    }

    private async generateImage(imagePrompt: string, type: "banner"|"inline"): Promise<string> {
        let image_size = {
            width: 0,
            height: 0
        }

        if(type === "banner") {
            image_size.width = 2000;
            image_size.height = 300;
        }

        if(type === "inline") {
            image_size.width = 1920;
            image_size.height = 1080;
        }

        const result = await fal.subscribe("fal-ai/flux/schnell", {
            input: {
                prompt: imagePrompt,
                image_size,
                num_inference_steps: 12
            },
            logs: true,
            onQueueUpdate: (update) => {
                if (update.status === "IN_PROGRESS") {
                    update.logs.map((log) => log.message).forEach(console.log);
                }
            },
        });

        console.log(result);

        return (result as any).images[0].url
    }
}

================
File: lib/inputmodal.ts
================
import { App, Modal } from "obsidian";

export class InputModal extends Modal {
    private input: string;
    private onSubmit: (input: string) => void;

    constructor(app: App, onSubmit: (input: string) => void) {
        super(app);
        this.onSubmit = onSubmit;
    }

	onOpen() {
        const { contentEl } = this;
        contentEl.empty();
        
        contentEl.createEl("h2", { text: "Enter additional details for image generation" });

        const inputEl = contentEl.createEl("textarea", {
            attr: {
                style: "width: 100%; height: 150px; margin-bottom: 10px;"
            }
        });
        inputEl.placeholder = "Enter your text here...";

        const buttonEl = contentEl.createEl("button", { 
            text: "Generate Image",
            attr: {
                style: "display: block; width: 100%;"
            }
        });
        
        buttonEl.addEventListener("click", () => {
            this.input = inputEl.value;
            this.close();
            this.onSubmit(this.input);
        });
    }

    onClose() {
        const { contentEl } = this;
        contentEl.empty();
    }
}

================
File: lib/settingstab.ts
================
import MyPlugin from "main";
import { App, PluginSettingTab, Setting } from "obsidian";

export class SettingsTab extends PluginSettingTab {
    plugin: MyPlugin;

    constructor(app: App, plugin: MyPlugin) {
        super(app, plugin);
        this.plugin = plugin;
    }

    display(): void {
        const { containerEl } = this;

        containerEl.empty();

        new Setting(containerEl)
            .setName('OpenAI API Key')
            .addText(text => text
                .setPlaceholder('Enter your key')
                .setValue(this.plugin.settings.openAiApiKey)
                .onChange(async (value) => {
                    this.plugin.settings.openAiApiKey = value;
                    await this.plugin.saveSettings();
                }));

        new Setting(containerEl)
            .setName('fal.ai API Key')
            .addText(text => text
                .setPlaceholder('Enter your key')
                .setValue(this.plugin.settings.falApiKey)
                .onChange(async (value) => {
                    this.plugin.settings.falApiKey = value;
                    await this.plugin.saveSettings();
                }));
                
    }
}

================
File: lib/types.ts
================
export interface MyPluginSettings {
    falApiKey: string;
    openAiApiKey: string;
}

export interface DocumentInfo {
    title: string;
    content: string;
}

================
File: LICENSE
================
MIT License

Copyright (c) 2024 Kyle Kingsberry

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: main.ts
================
import { ImageGen } from 'lib/imagegenv2';
import { InputModal } from 'lib/inputmodal';
import { SettingsTab } from 'lib/settingstab';
import { DocumentInfo, MyPluginSettings } from 'lib/types';
import { Editor, MarkdownView, Notice, Plugin, TFile } from 'obsidian';

const DEFAULT_SETTINGS: MyPluginSettings = {
    openAiApiKey: '',
    falApiKey: ''
}

interface IGeneratedImagePath {
    obsidianRelUrl: string;
    fullUrl: string;
}

export default class MyPlugin extends Plugin {
    settings: MyPluginSettings;
    imageGen: ImageGen;

    async onload() {
        await this.loadSettings();
        this.imageGen = new ImageGen(this.settings.falApiKey, this.settings.openAiApiKey);

        this.addCommand({
            id: 'generate-banner-image',
            name: 'Generate Banner Image (Flux AI)',
            callback: () => this.generateImage("banner")
        });

        this.addCommand({
            id: 'generate-inline-image',
            name: 'Generate Inline Image (Flux AI, 4:3)',
            callback: () => this.generateImage("inline")
        })

        this.addSettingTab(new SettingsTab(this.app, this));
    }

	async generateImage(type: "banner"|"inline") {
        if (!this.settings.openAiApiKey || !this.settings.falApiKey) {
            new Notice('Please enter your OpenAI and fal.ai API keys in the settings');
            return;
        }

        new InputModal(this.app, async (input: string) => {
            try {
                const activeFile = this.app.workspace.getActiveFile();
                if (!(activeFile instanceof TFile)) {
                    new Notice('No file is currently open');
                    return;
                }

                new Notice('Generating image...');
                const docInfo = await this.getCurrentFileInfo();

                // Use the user input in the image generation process
                const imageGenRes = await this.imageGen.generate(input, docInfo, type);
                const imageUrl = imageGenRes.imageUrl;
                
                new Notice('Saving image to vault...');
                const imageInfo = await this.saveImageToVault(imageUrl);
                
                if(type == "banner") {
                    await this.prependImageToDocument(activeFile, imageInfo.obsidianRelUrl);
                    new Notice('Image generated, saved, and prepended to the document');
                } else if(type == "inline") {
                    await this.insertInlineImageAtCursor(imageInfo.fullUrl);
                    const revisedImageGenRes = await this.imageGen.generateRevised(imageGenRes.imageDescription, imageGenRes.imagePrompt, imageGenRes.imageUrl);
                    
                    new Notice('Saving image to vault...');
                    const revisedInfo = await this.saveImageToVault(revisedImageGenRes.imageUrl);
                    await this.insertInlineImageAtCursor(revisedInfo.fullUrl);
                    new Notice('Image generated, saved, and inserted at cursor');
                }
            } catch (error) {
                console.error("Error in image generation process:", error);
                new Notice('Failed to complete the image generation process');
            }
        }).open();
    }

    async insertInlineImageAtCursor(imagePath: string) {
        const activeView = this.app.workspace.getActiveViewOfType(MarkdownView);
        if (!activeView) {
            new Notice('No active document');
            return;
        }

        const editor = activeView.editor;
        const cursor = editor.getCursor();
        const line = editor.getLine(cursor.line);
        const beforeCursor = line.slice(0, cursor.ch);
        const afterCursor = line.slice(cursor.ch);

        const newLine = `${beforeCursor}![[${imagePath}]]${afterCursor}`;
        editor.setLine(cursor.line, newLine);
    }

    onunload() {}

    async loadSettings() {
        this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
    }

    async saveSettings() {
        await this.saveData(this.settings);
        this.imageGen = new ImageGen(this.settings.falApiKey, this.settings.openAiApiKey);
    }

    async getCurrentFileInfo(): Promise<DocumentInfo> {
        const activeFile = this.app.workspace.getActiveFile();
        if (activeFile instanceof TFile) {
            const content = await this.app.vault.read(activeFile);
            return {
                title: activeFile.basename,
                content: content
            };
        }
        return {
            title: "",
            content: ""
        };
    }

	async saveImageToVault(imageUrl: string): Promise<IGeneratedImagePath> {
        try {
            const response = await fetch(imageUrl);
            
            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }
            
            const arrayBuffer = await response.arrayBuffer();
            
            const fileName = `generated_image_${Date.now()}.png`;
            const filePath = `ai_banners/${fileName}`;
            
            const file = await this.app.vault.createBinary(filePath, arrayBuffer);
            
            return {
                obsidianRelUrl: filePath,
                fullUrl: file.path
            };
        } catch (error) {
            console.error("Error saving image to vault:", error);
            throw new Error("Failed to save image to vault");
        }
    }

    async prependImageToDocument(file: TFile, imagePath: string) {
        const content = await this.app.vault.read(file);
        const updatedContent = `![[${imagePath}|banner]]\n${content}`;
        await this.app.vault.modify(file, updatedContent);
    }
}

================
File: manifest.json
================
{
	"id": "ai-banner",
	"name": "AI Banner",
	"version": "1.0.1",
	"minAppVersion": "0.15.0",
	"description": "Adds a command to the command palatte to generate a banner for the currently open document.",
	"author": "Kyle K",
	"authorUrl": "https://www.linkedin.com/in/kyle-kingsberry-9690a7109/",
	"isDesktopOnly": false
}

================
File: package.json
================
{
	"name": "obsidian-sample-plugin",
	"version": "1.0.0",
	"description": "This is a sample plugin for Obsidian (https://obsidian.md)",
	"main": "main.js",
	"scripts": {
		"dev": "node esbuild.config.mjs",
		"prepare": "cpy manifest.json versions.json main.js styles.css dist",
		"deploy:local": "rimraf \"C:/Users/kking/OneDrive/Documents/School/.obsidian/plugins/ai-banner\" && ncp dist \"C:/Users/kking/OneDrive/Documents/School/.obsidian/plugins/ai-banner\"",
		"build": "tsc -noEmit -skipLibCheck && node esbuild.config.mjs production && npm run prepare && npm run deploy:local",
		"version": "node version-bump.mjs && git add manifest.json versions.json"
	},
	"keywords": [],
	"author": "",
	"license": "MIT",
	"devDependencies": {
		"@types/node": "^16.11.6",
		"@typescript-eslint/eslint-plugin": "5.29.0",
		"@typescript-eslint/parser": "5.29.0",
		"builtin-modules": "3.3.0",
		"esbuild": "0.17.3",
		"obsidian": "latest",
		"tslib": "2.4.0",
		"typescript": "4.7.4"
	},
	"dependencies": {
		"@fal-ai/serverless-client": "^0.14.2",
		"axios": "^1.7.4",
		"cpy-cli": "^5.0.0",
		"ncp": "^2.0.0",
		"openai": "^4.56.0"
	}
}

================
File: README.md
================
# Obsidian Banner Generator Plugin

Enhance your Obsidian documents with stunning, AI-generated banner images using GPT and Flux AI.

## Features

- Create custom banner images tailored to your document's content
- Seamlessly integrate with Obsidian's interface
- Automatically save generated images to your vault
- Effortlessly prepend banner images to your documents

## Prerequisites

Before using this plugin, you'll need:

- An OpenAI API key
- A Flux AI (fal.ai) API key

## Installation

1. Launch Obsidian and navigate to Settings > Community Plugins
2. Disable Safe Mode
3. Click "Browse" and search for "Banner Generator"
4. Install and enable the plugin

## Setup

1. Go to Settings > Banner Generator
2. Enter your OpenAI API key
3. Enter your Flux AI (fal.ai) API key

## How to Use

1. Open any document in Obsidian
2. Access the command palette (Ctrl/Cmd + P)
3. Search for and select "Generate Banner Image (Flux AI)"
4. (Optional) Provide a brief description of your document's purpose
   - For longer documents, the plugin can effectively use the existing content as context
   - For shorter documents or when you want more control, add a description to guide the image generation
5. Wait briefly while your custom banner image is created and added to your document

## Behind the Scenes

1. The plugin analyzes your document's title, content, and any additional input you provide
2. It sends this information to GPT-4 to create an enhanced, contextual prompt
3. The refined prompt is then processed by Flux AI to generate a unique image
4. The resulting image is saved in your Obsidian vault and automatically prepended to your document

## Troubleshooting

If you encounter issues:

- Verify that your API keys are correctly entered in the plugin settings
- Ensure you have a stable internet connection
- For any errors, check the console log and report issues on our GitHub page

## Support and Feedback

We welcome your input! If you experience any problems or have ideas for improvements, please open an issue on our GitHub repository.

## License
This project is licensed under the MIT License. See the LICENSE file for details.
---

Elevate your Obsidian documents with captivating, AI-generated banners!

================
File: styles.css
================
.markdown-source-view:has(*[alt="banner"]),
.markdown-preview-view:has(*[alt="banner"]) {
    --banner-height: 200px;
}

/* Margin above inline title and frontmatter. */
.markdown-source-view:has(*[alt="banner"]).is-live-preview .cm-sizer,
.markdown-preview-view:has(*[alt="banner"]).markdown-preview-view .markdown-preview-pusher {
    padding-top: var(--banner-height);
}

.markdown-source-view:has(*[alt="banner"]).is-live-preview .image-embed:has(img[alt="banner"]:first-child),
.markdown-preview-view:has(*[alt="banner"]).markdown-preview-view span[alt="banner"]:first-child {
    display: contents;
}

/* Positions banner image fix to the top with bottom fade. */
.markdown-source-view:has(*[alt="banner"]).is-live-preview .image-embed img[alt="banner"]:first-child,
.markdown-preview-view:has(*[alt="banner"]).markdown-preview-view img[alt="banner"]:first-child {
    display: block;
    position: absolute;
    top: 0;
    left: 0;
    object-fit: cover;
    height: var(--banner-height);
    margin: 0 auto;
    width: 100%;
    pointer-events: auto;
    background: none !important;
    border: none !important;
    border-radius: none !important;
    box-shadow: none !important;
    mask-image: linear-gradient(to bottom, black 75%, transparent 100%);
    -webkit-mask-image: linear-gradient(to bottom, black 75%, transparent 100%);
}

================
File: tsconfig.json
================
{
  "compilerOptions": {
    "baseUrl": ".",
    "inlineSourceMap": true,
    "inlineSources": true,
    "module": "ESNext",
    "target": "ES6",
    "allowJs": true,
    "noImplicitAny": true,
    "moduleResolution": "node",
    "importHelpers": true,
    "isolatedModules": true,
    "strictNullChecks": true,
    "lib": [
      "DOM",
      "ES5",
      "ES6",
      "ES7"
    ]
  },
  "include": [
    "**/*.ts"
  ]
}

================
File: version-bump.mjs
================
import { readFileSync, writeFileSync } from "fs";

const targetVersion = process.env.npm_package_version;

// read minAppVersion from manifest.json and bump version to target version
let manifest = JSON.parse(readFileSync("manifest.json", "utf8"));
const { minAppVersion } = manifest;
manifest.version = targetVersion;
writeFileSync("manifest.json", JSON.stringify(manifest, null, "\t"));

// update versions.json with target version and minAppVersion from manifest.json
let versions = JSON.parse(readFileSync("versions.json", "utf8"));
versions[targetVersion] = minAppVersion;
writeFileSync("versions.json", JSON.stringify(versions, null, "\t"));

================
File: versions.json
================
{
	"1.0.0": "0.15.0"
}
